# Deployer - Deploying flows programmatically

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file. -->

The `Deployer` class allows you to manage [production deployments](/production/introduction) programmatically. For an overview, see [Deploying flows programmatically](/metaflow/managing-flows/deployer).

Metaflow supports [various production orchestrators](/production/scheduling-metaflow-flows/introduction), each offering slightly different functionalities. All of them operate with the same high-level interfaces, exposed through the `Deployer` API:

1. Start by instantiating the top-level `Deployer` object.
2. Choose a production orchestrator through the functions of `Deployer`.
3. Deploy a flow by calling an implementation-specific `create()` function that returns a `DeployedFlow` representing a flow that is deployed but not yet running.
4. The `DeployedFlow` is ready to execute automatically if it is scheduled with [`@schedule`](/api/flow-decorators/schedule), [`@trigger`](/api/flow-decorators/trigger), 
and [`@trigger_on_finish`](/api/flow-decorators/trigger_on_finish) decorators.
5. Optionally, you can trigger a run explictly by calling `DeployedFlow.trigger()` that returns a `TriggeredRun`  representing a run that will start executing.
6. Once the run has started executing, `TriggeredRun.run` returns a corresponding [`Run` object](/api/client#run).

### Example

```python
import time
from metaflow import Deployer
deployed_flow = Deployer('helloflow.py').argo_workflows().create()
print('Production token', deployed_flow.production_token)
triggered_run = deployed_flow.trigger()
while triggered_run.run is None:
    print(f'Waiting for the run to start')
    time.sleep(1)
print('Run started', triggered_run.run)
print('Terminating the flow', triggered_run.terminate())
```

Note that you can replace `argo_workflows()` above with `step_functions()` without changing anything
else in the code.

In addition to this basic functionality, each implementation-specific object exposes additional functions for managing deployed flows and runs, as documented below.

## Common `Deployer`


<DocSection type="class" name="Deployer" module="metaflow" show_import="False" heading_level="3" link="https://github.com/Netflix/metaflow/tree/master/">
<SigArgSection>
<SigArg name="flow_file, show_output=True, profile=None, env=None, cwd=None, **kwargs" />
</SigArgSection>
<Description summary="Use the `Deployer` class to configure and access one of the production\norchestrators supported by Metaflow." />
<ParamSection name="Parameters">
	<Parameter name="flow_file" type="str" desc="Path to the flow file to deploy." />
	<Parameter name="show_output" type="bool, default True" desc="Show the 'stdout' and 'stderr' to the console by default." />
	<Parameter name="profile" type="Optional[str], default None" desc="Metaflow profile to use for the deployment. If not specified, the default\nprofile is used." />
	<Parameter name="env" type="Optional[Dict[str, str]], default None" desc="Additional environment variables to set for the deployment." />
	<Parameter name="cwd" type="Optional[str], default None" desc="The directory to run the subprocess in; if not specified, the current\ndirectory is used." />
	<Parameter name="file_read_timeout" type="int, default 3600" desc="The timeout until which we try to read the deployer attribute file." />
	<Parameter name="**kwargs" type="Any" desc="Additional arguments that you would pass to `python myflow.py` before\nthe deployment command." />
</ParamSection>
</DocSection>



<DocSection type="method" name="Deployer.argo_workflows" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/__main__.py#L11">
<SigArgSection>
<SigArg name="self" />
</SigArgSection>
<Description summary="Returns a deployer specific to Argo Workflows." />
<ParamSection name="Returns">
	<Parameter type="ArgoWorkflowsDeployer" desc="a deployer class specific to Argo Workflows" />
</ParamSection>
</DocSection>



<DocSection type="method" name="Deployer.step_functions" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/__main__.py#L21">
<SigArgSection>
<SigArg name="self" />
</SigArgSection>
<Description summary="Returns a deployer specific to Step Functions." />
<ParamSection name="Returns">
	<Parameter type="StepFunctionsDeployer" desc="a deployer class specific to Step Functions" />
</ParamSection>
</DocSection>


## Deploy Argo Workflows with `ArgoWorkflowsDeployer`


<DocSection type="method" name="ArgoWorkflowsDeployer.create" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_workflows_deployer.py#L49">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Create a new ArgoWorkflow deployment." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize using this production token. Required when re-deploying an existing flow\nfor the first time. The token is cached in METAFLOW_HOME." />
	<Parameter name="generate_new_token" type="bool, optional, default False" desc="Generate a new production token for this flow. Moves the production flow to a new namespace." />
	<Parameter name="given_token" type="str, optional, default None" desc="Use the given production token for this flow. Moves the production flow to the given namespace." />
	<Parameter name="tags" type="List[str], optional, default None" desc="Annotate all objects produced by Argo Workflows runs with these tags." />
	<Parameter name="user_namespace" type="str, optional, default None" desc="Change the namespace from the default (production token) to the given tag." />
	<Parameter name="only_json" type="bool, optional, default False" desc="Only print out JSON sent to Argo Workflows without deploying anything." />
	<Parameter name="max_workers" type="int, optional, default 100" desc="Maximum number of parallel processes." />
	<Parameter name="workflow_timeout" type="int, optional, default None" desc="Workflow timeout in seconds." />
	<Parameter name="workflow_priority" type="int, optional, default None" desc="Workflow priority as an integer. Higher priority workflows are processed first\nif Argo Workflows controller is configured to process limited parallel workflows." />
	<Parameter name="auto_emit_argo_events" type="bool, optional, default True" desc="Auto emits Argo Events when the run completes successfully." />
	<Parameter name="notify_on_error" type="bool, optional, default False" desc="Notify if the workflow fails." />
	<Parameter name="notify_on_success" type="bool, optional, default False" desc="Notify if the workflow succeeds." />
	<Parameter name="notify_slack_webhook_url" type="str, optional, default ''" desc="Slack incoming webhook url for workflow success/failure notifications." />
	<Parameter name="notify_pager_duty_integration_key" type="str, optional, default ''" desc="PagerDuty Events API V2 Integration key for workflow success/failure notifications." />
	<Parameter name="enable_heartbeat_daemon" type="bool, optional, default False" desc="Use a daemon container to broadcast heartbeats." />
	<Parameter name="deployer_attribute_file" type="str, optional, default None" desc="Write the workflow name to the specified file. Used internally for Metaflow's Deployer API." />
	<Parameter name="enable_error_msg_capture" type="bool, optional, default True" desc="Capture stack trace of first failed task in exit hook." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="ArgoWorkflowsDeployedFlow" desc="The Flow deployed to Argo Workflows." />
</ParamSection>
</DocSection>


### Manage a flow deployed on Argo Workflows with `ArgoWorkflowsDeployedFlow`


<DocSection type="property" name="ArgoWorkflowsDeployedFlow.production_token" module="metaflow.plugins.argo.argo_workflows_deployer_objects" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/">

<Description summary="Get the production token for the deployed flow.\n" />
<ParamSection name="Returns">
<Parameter type="str, optional" desc="The production token, None if it cannot be retrieved." />
</ParamSection>
</DocSection>



<DocSection type="method" name="ArgoWorkflowsDeployedFlow.trigger" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_workflows_deployer_objects.py#L307">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Trigger a new run for the deployed flow." />
<ParamSection name="Parameters">
	<Parameter name="**kwargs" type="Any" desc="Additional arguments to pass to the trigger command,\n`Parameters` in particular." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="ArgoWorkflowsTriggeredRun" desc="The triggered run instance." />
</ParamSection>
<ParamSection name="Raises">
	<Parameter type="Exception" desc="If there is an error during the trigger process." />
</ParamSection>
</DocSection>



<DocSection type="method" name="ArgoWorkflowsDeployedFlow.delete" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_workflows_deployer_objects.py#L276">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Delete the deployed workflow template." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize the deletion with a production token." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="bool" desc="True if the command was successful, False otherwise." />
</ParamSection>
</DocSection>


### Manage a run triggered on Argo Workflows with `ArgoWorkflowsTriggeredRun`


<DocSection type="property" name="TriggeredRun.run" module="metaflow.runner.deployer" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/">

<Description summary="Retrieve the `Run` object for the triggered run.\n\nNote that Metaflow `Run` becomes available only when the `start` task\nhas started executing.\n" />
<ParamSection name="Returns">
<Parameter type="Run, optional" desc="Metaflow Run object if the `start` step has started executing, otherwise None." />
</ParamSection>
</DocSection>



<DocSection type="method" name="ArgoWorkflowsTriggeredRun.terminate" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_workflows_deployer_objects.py#L136">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Terminate the running workflow." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize the termination with a production token." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="bool" desc="True if the command was successful, False otherwise." />
</ParamSection>
</DocSection>



<DocSection type="method" name="ArgoWorkflowsTriggeredRun.suspend" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_workflows_deployer_objects.py#L68">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Suspend the running workflow." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize the suspension with a production token." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="bool" desc="True if the command was successful, False otherwise." />
</ParamSection>
</DocSection>



<DocSection type="method" name="ArgoWorkflowsTriggeredRun.unsuspend" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/argo/argo_workflows_deployer_objects.py#L102">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Unsuspend the suspended workflow." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize the unsuspend with a production token." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="bool" desc="True if the command was successful, False otherwise." />
</ParamSection>
</DocSection>



<DocSection type="property" name="ArgoWorkflowsTriggeredRun.status" module="metaflow.plugins.argo.argo_workflows_deployer_objects" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/">

<Description summary="Get the status of the triggered run.\n" />
</DocSection>


## Deploy Step Functions with `StepFunctionsDeployer`


<DocSection type="method" name="StepFunctionsDeployer.create" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/step_functions/step_functions_deployer.py#L49">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Create a new AWS Step Functions State Machine deployment." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize using this production token. Required when re-deploying an existing flow\nfor the first time. The token is cached in METAFLOW_HOME." />
	<Parameter name="generate_new_token" type="bool, optional, default False" desc="Generate a new production token for this flow. Moves the production flow to a new namespace." />
	<Parameter name="given_token" type="str, optional, default None" desc="Use the given production token for this flow. Moves the production flow to the given namespace." />
	<Parameter name="tags" type="List[str], optional, default None" desc="Annotate all objects produced by AWS Step Functions runs with these tags." />
	<Parameter name="user_namespace" type="str, optional, default None" desc="Change the namespace from the default (production token) to the given tag." />
	<Parameter name="only_json" type="bool, optional, default False" desc="Only print out JSON sent to AWS Step Functions without deploying anything." />
	<Parameter name="max_workers" type="int, optional, default 100" desc="Maximum number of parallel processes." />
	<Parameter name="workflow_timeout" type="int, optional, default None" desc="Workflow timeout in seconds." />
	<Parameter name="log_execution_history" type="bool, optional, default False" desc="Log AWS Step Functions execution history to AWS CloudWatch Logs log group." />
	<Parameter name="use_distributed_map" type="bool, optional, default False" desc="Use AWS Step Functions Distributed Map instead of Inline Map for defining foreach\ntasks in Amazon State Language." />
	<Parameter name="deployer_attribute_file" type="str, optional, default None" desc="Write the workflow name to the specified file. Used internally for Metaflow's Deployer API." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="StepFunctionsDeployedFlow" desc="The Flow deployed to AWS Step Functions." />
</ParamSection>
</DocSection>


### Manage a flow deployed on Step Functions with `StepFunctionsDeployedFlow`


<DocSection type="property" name="StepFunctionsDeployedFlow.production_token" module="metaflow.plugins.aws.step_functions.step_functions_deployer_objects" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/">

<Description summary="Get the production token for the deployed flow.\n" />
<ParamSection name="Returns">
<Parameter type="str, optional" desc="The production token, None if it cannot be retrieved." />
</ParamSection>
</DocSection>



<DocSection type="method" name="StepFunctionsDeployedFlow.trigger" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/step_functions/step_functions_deployer_objects.py#L171">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Trigger a new run for the deployed flow." />
<ParamSection name="Parameters">
	<Parameter name="**kwargs" type="Any" desc="Additional arguments to pass to the trigger command,\n`Parameters` in particular" />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="StepFunctionsTriggeredRun" desc="The triggered run instance." />
</ParamSection>
<ParamSection name="Raises">
	<Parameter type="Exception" desc="If there is an error during the trigger process." />
</ParamSection>
</DocSection>



<DocSection type="method" name="StepFunctionsDeployedFlow.delete" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/step_functions/step_functions_deployer_objects.py#L140">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Delete the deployed state machine." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize the deletion with a production token." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="bool" desc="True if the command was successful, False otherwise." />
</ParamSection>
</DocSection>



<DocSection type="method" name="StepFunctionsDeployedFlow.list_runs" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/step_functions/step_functions_deployer_objects.py#L83">
<SigArgSection>
<SigArg name="self" /><SigArg name="states" type="Optional" default="None" />
</SigArgSection>
<Description summary="List runs of the deployed flow." />
<ParamSection name="Parameters">
	<Parameter name="states" type="List[str], optional, default None" desc="A list of states to filter the runs by. Allowed values are:\nRUNNING, SUCCEEDED, FAILED, TIMED_OUT, ABORTED.\nIf not provided, all states will be considered." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="List[StepFunctionsTriggeredRun]" desc="A list of TriggeredRun objects representing the runs of the deployed flow." />
</ParamSection>
<ParamSection name="Raises">
	<Parameter type="ValueError" desc="If any of the provided states are invalid or if there are duplicate states." />
</ParamSection>
</DocSection>


### Manage a run triggered on Step Functions with `StepFunctionsTriggeredRun`


<DocSection type="property" name="TriggeredRun.run" module="metaflow.runner.deployer" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/">

<Description summary="Retrieve the `Run` object for the triggered run.\n\nNote that Metaflow `Run` becomes available only when the `start` task\nhas started executing.\n" />
<ParamSection name="Returns">
<Parameter type="Run, optional" desc="Metaflow Run object if the `start` step has started executing, otherwise None." />
</ParamSection>
</DocSection>



<DocSection type="method" name="StepFunctionsTriggeredRun.terminate" module="metaflow" show_import="False" heading_level="4" link="https://github.com/Netflix/metaflow/tree/master/metaflow/plugins/aws/step_functions/step_functions_deployer_objects.py#L17">
<SigArgSection>
<SigArg name="self" /><SigArg name="**kwargs" />
</SigArgSection>
<Description summary="Terminate the running state machine execution." />
<ParamSection name="Parameters">
	<Parameter name="authorize" type="str, optional, default None" desc="Authorize the termination with a production token." />
</ParamSection>
<ParamSection name="Returns">
	<Parameter type="bool" desc="True if the command was successful, False otherwise." />
</ParamSection>
</DocSection>

