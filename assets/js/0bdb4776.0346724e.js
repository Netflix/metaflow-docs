"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[1099],{6416:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var n=a(7462),o=(a(7294),a(3905)),r=a(2004);const i={},s="Computing at Scale",l={unversionedId:"scaling/remote-tasks/introduction",id:"scaling/remote-tasks/introduction",title:"Computing at Scale",description:"Metaflow makes it easy to run compute in the cloud. Instead of prescribing one paradigm for all",source:"@site/docs/scaling/remote-tasks/introduction.md",sourceDirName:"scaling/remote-tasks",slug:"/scaling/remote-tasks/introduction",permalink:"/scaling/remote-tasks/introduction",draft:!1,editUrl:"https://github.dev/Netflix/metaflow-docs/blob/master/docs/scaling/remote-tasks/introduction.md",tags:[],version:"current",frontMatter:{},sidebar:"python",previous:{title:"Scalable Compute and Data",permalink:"/scaling/introduction"},next:{title:"Requesting Compute Resources",permalink:"/scaling/remote-tasks/requesting-resources"}},p={},c=[{value:"Rapid development with local execution",id:"rapid-development-with-local-execution",level:2},{value:"Parallelizing Python over multiple CPU cores",id:"parallelizing-python-over-multiple-cpu-cores",level:3},{value:"Requesting compute <code>@resources</code>",id:"requesting-compute-resources",level:2},{value:"Requesting GPUs and other hardware accelerators",id:"requesting-gpus-and-other-hardware-accelerators",level:3},{value:"Saving money with spot instances",id:"saving-money-with-spot-instances",level:3},{value:"Executing steps in parallel",id:"executing-steps-in-parallel",level:2},{value:"Running many tasks in parallel with <code>foreach</code>",id:"running-many-tasks-in-parallel-with-foreach",level:2},{value:"Options for controlling parallelism",id:"options-for-controlling-parallelism",level:3},{value:"Distributed computing with ephemeral compute clusters",id:"distributed-computing-with-ephemeral-compute-clusters",level:2}],u={toc:c};function m(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"computing-at-scale"},"Computing at Scale"),(0,o.kt)("p",null,"Metaflow makes it easy to run compute in the cloud. Instead of prescribing one paradigm for all\ncompute needs, Metaflow allows you to mix and match various patterns of scalable compute,\nkeeping simple things simple while making advanced use cases possible."),(0,o.kt)("p",null,"When your needs are modest, you can\nrun Metaflow as any Python code, such as a notebook or a local script. When you need more\ncompute power, say to train a model on GPUs or to handle a large dataframe, you can get the\njob done by adding a line code. Or, you can execute even thousands of such tasks in parallel\nor train a large model, such as an LLM, over many GPUs."),(0,o.kt)("p",null,"When your needs grow, you can even ",(0,o.kt)("a",{parentName:"p",href:"/scaling/remote-tasks/requesting-resources#mixing-cloud-environments"},"mix and match various compute\nenvironments")," to\ncreate advanced workflows that operate across local, on-premise data centers, and\nvarious public clouds."),(0,o.kt)("p",null,"Below, we provide an overview of the patterns of compute that Metaflow supports with pointers\nfor more details. Importantly, you can mix and match these patterns freely, even in a single\nflow."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"To enable the cloud computing capabilities of Metaflow - ",(0,o.kt)("inlineCode",{parentName:"p"},"@batch")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"@kubernetes")," - you need to\n",(0,o.kt)("a",{parentName:"p",href:"/getting-started/infrastructure"},"deploy a Metaflow stack")," first. To test these concepts\nbefore deploying, ",(0,o.kt)("a",{parentName:"p",href:"https://outerbounds.com/sandbox/"},"try the Metaflow Sandbox"),".")),(0,o.kt)("h2",{id:"rapid-development-with-local-execution"},"Rapid development with local execution"),(0,o.kt)("p",null,"When you run a flow without special decorators, e.g.\n",(0,o.kt)("a",{parentName:"p",href:"/metaflow/basics#linear"},"run ",(0,o.kt)("inlineCode",{parentName:"a"},"LinearFlow")," by typing ",(0,o.kt)("inlineCode",{parentName:"a"},"python linear.py run")),",\nthe flow runs locally on your computer like any Python script or a notebook."),(0,o.kt)(r.Z,{playsinline:!0,laying:!0,controls:!0,muted:!0,loop:!0,url:"/assets/compute1.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,o.kt)("p",null,"This allows you to develop and test code rapidly without having to rely on any infrastructure\noutside your workstation."),(0,o.kt)("p",null,"Running your code as a flow can provide an immediate performance benefit: If your flow has\n",(0,o.kt)("a",{parentName:"p",href:"/metaflow/basics#branch"},"branches")," or ",(0,o.kt)("a",{parentName:"p",href:"/metaflow/basics#foreach"},"foreaches"),",\nMetaflow leverages multiple CPU cores to speed up compute by running parallel tasks as separate\nprocesses. In addition to Metaflow parallelizing tasks, you can speed up compute by using\noptimized Python libraries such as ",(0,o.kt)("a",{parentName:"p",href:"https://pytorch.org/"},"PyTorch")," to leverage GPUs or a library\nlike\n",(0,o.kt)("a",{parentName:"p",href:"https://xgboost.readthedocs.io/en/stable/"},"XGBoost")," that can utilize multiple CPU cores."),(0,o.kt)("h3",{id:"parallelizing-python-over-multiple-cpu-cores"},"Parallelizing Python over multiple CPU cores"),(0,o.kt)("p",null,"If you need to execute a medium amount of compute - too much to handle in sequential Python\ncode but not enough to warrant parallel tasks using ",(0,o.kt)("inlineCode",{parentName:"p"},"foreach")," - ",(0,o.kt)("a",{parentName:"p",href:"multicore"},"Metaflow provides a helper function,\n",(0,o.kt)("inlineCode",{parentName:"a"},"parallel_map"))," that parallelizes execution of a Python function over multiple CPU cores.\nFor instance, you can use ",(0,o.kt)("inlineCode",{parentName:"p"},"parallel_map")," to process a list of 10M items in batches of 1M items\nin parallel."),(0,o.kt)("h2",{id:"requesting-compute-resources"},"Requesting compute ",(0,o.kt)("inlineCode",{parentName:"h2"},"@resources")),(0,o.kt)("p",null,"If your job requires more resources than what is available on your workstation, e.g. more\nmemory or more GPUs, Metaflow makes it easy to run the task remotely on a cloud instance:\n",(0,o.kt)("a",{parentName:"p",href:"requesting-resources"},"Simply annotate the step with the ",(0,o.kt)("inlineCode",{parentName:"a"},"@resources")," decorator"),"."),(0,o.kt)(r.Z,{playsinline:!0,playing:!0,controls:!0,muted:!0,loop:!0,url:"/assets/compute2.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,o.kt)("p",null,"In this case, Metaflow executes the task remotely in the cloud using ",(0,o.kt)("a",{parentName:"p",href:"/getting-started/infrastructure"},"one of the supported compute\nbackends"),", AWS Batch or Kubernetes."),(0,o.kt)("p",null,"This is often the easiest way\nto scale up compute to handle larger datasets or models. It is like getting a bigger computer with\na line of code. While larger cloud instances cost more, they are only needed for as long as a\n",(0,o.kt)("inlineCode",{parentName:"p"},"@step")," executes, so this approach can be cost-effective as well. This manner of scaling is called\n",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Scalability#Vertical_or_scale_up"},(0,o.kt)("em",{parentName:"a"},"vertical scaling")),"."),(0,o.kt)("h3",{id:"requesting-gpus-and-other-hardware-accelerators"},"Requesting GPUs and other hardware accelerators"),(0,o.kt)("p",null,"ML/AI workloads often require hardware acceleration such as GPUs. Learn more on ",(0,o.kt)("a",{parentName:"p",href:"gpu-compute"},"a dedicated\npage about hardware-accelerated compute"),"."),(0,o.kt)("h3",{id:"saving-money-with-spot-instances"},"Saving money with spot instances"),(0,o.kt)("p",null,"You can reduce your cloud costs by utilizing spot instances. Besides ",(0,o.kt)("a",{parentName:"p",href:"/scaling/failures#retrying-tasks-with-the-retry-decorator"},"retrying tasks\nautomatically")," when spot instances\nare terminated, Metaflow allows you to ",(0,o.kt)("a",{parentName:"p",href:"/scaling/remote-tasks/spot-instances"},"exit and clean up tasks gracefully"),"\nbefore termination."),(0,o.kt)("h2",{id:"executing-steps-in-parallel"},"Executing steps in parallel"),(0,o.kt)("p",null,"If you want to execute two or more ",(0,o.kt)("inlineCode",{parentName:"p"},"@step"),"s in parallel, ",(0,o.kt)("a",{parentName:"p",href:"/metaflow/basics#branch"},"make them ",(0,o.kt)("inlineCode",{parentName:"a"},"branch")),"."),(0,o.kt)(r.Z,{playsinline:!0,playing:!0,controls:!0,muted:!0,loop:!0,url:"/assets/compute3.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,o.kt)("p",null,"When you run a flow with branches locally, each ",(0,o.kt)("inlineCode",{parentName:"p"},"@step")," is run in a process of its own, taking\nadvantage of multiple CPU cores in your workstation to speed up processing. When you ",(0,o.kt)("a",{parentName:"p",href:"requesting-resources"},"execute the\nflow (or some of its steps) remotely"),", each ",(0,o.kt)("inlineCode",{parentName:"p"},"@step")," is\nrun in a separate container, allowing you to run even thousands of steps in parallel."),(0,o.kt)("p",null,"Branches come in handy in two scenarios:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"You have separate operations that can be executed independently.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"You want to allocate separate ",(0,o.kt)("inlineCode",{parentName:"p"},"@resources")," (or other decorators) for different sets of data, e.g.\nto build a small model with CPUs and a large one with GPUs. Just create branches, each with their\nown set of decorators."))),(0,o.kt)("h2",{id:"running-many-tasks-in-parallel-with-foreach"},"Running many tasks in parallel with ",(0,o.kt)("inlineCode",{parentName:"h2"},"foreach")),(0,o.kt)("p",null,"A very common scenario in ML, AI, and data processing is to run the same operation, e.g. data\ntransformation or model training, for each shard of data or a set of parameters."),(0,o.kt)(r.Z,{playsinline:!0,playing:!0,controls:!0,muted:!0,loop:!0,url:"/assets/compute4.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,o.kt)("p",null,"Metaflow's ",(0,o.kt)("a",{parentName:"p",href:"/metaflow/basics#foreach"},(0,o.kt)("inlineCode",{parentName:"a"},"foreach"))," is similar to\n",(0,o.kt)("a",{parentName:"p",href:"https://realpython.com/python-map-function/"},"Python's built-in ",(0,o.kt)("inlineCode",{parentName:"a"},"map")," function")," which allows\nyou to apply a function - or in the case of Metaflow, a ",(0,o.kt)("inlineCode",{parentName:"p"},"@step")," - to all elements in a list."),(0,o.kt)("p",null,"The difference to ",(0,o.kt)("inlineCode",{parentName:"p"},"branch")," is that ",(0,o.kt)("inlineCode",{parentName:"p"},"foreach")," applies ",(0,o.kt)("strong",{parentName:"p"},"the same operation")," to all elements,\nutilizing ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Data_parallelism"},(0,o.kt)("em",{parentName:"a"},"data parallelism")),", whereas ",(0,o.kt)("inlineCode",{parentName:"p"},"branch"),"\napplies ",(0,o.kt)("strong",{parentName:"p"},"a different operation")," to each, utilizing\n",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Task_parallelism"},(0,o.kt)("em",{parentName:"a"},"task parallelism")),"."),(0,o.kt)("p",null,"The superpower of Metaflow is that you can ",(0,o.kt)("a",{parentName:"p",href:"requesting-resources"},"run these tasks in parallel"),",\nprocessing even thousands of items concurrently in the cloud. Hence you can use foreaches to\nprocess large datasets, train many models, or run hyperparameter searches in parallel, that is,\nexecute any ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Embarrassingly_parallel"},(0,o.kt)("em",{parentName:"a"},"embarrassingly parallel")),"\noperations that can benefit from\n",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Scalability#Horizontal_or_scale_out"},(0,o.kt)("em",{parentName:"a"},"horizontal scaling")),"."),(0,o.kt)("h3",{id:"options-for-controlling-parallelism"},"Options for controlling parallelism"),(0,o.kt)("p",null,"Note that regardless of the size of your list to ",(0,o.kt)("inlineCode",{parentName:"p"},"foreach")," over, you can control the number\nof tasks actually run in parallel with ",(0,o.kt)("a",{parentName:"p",href:"#"},"the ",(0,o.kt)("inlineCode",{parentName:"a"},"--max-workers")," flag"),". Also you will want to\n",(0,o.kt)("a",{parentName:"p",href:"#"},"increase ",(0,o.kt)("inlineCode",{parentName:"a"},"--max-num-splits")," when you list is long"),"."),(0,o.kt)("h2",{id:"distributed-computing-with-ephemeral-compute-clusters"},"Distributed computing with ephemeral compute clusters"),(0,o.kt)("p",null,"The most advanced pattern of compute that Metaflow supports is distributed computing. In\nthis case, Metaflow sets up a cluster of instances on the fly which can communicate with\neach other, e.g. to train a Large Language Model (LLM) over many GPU instances."),(0,o.kt)(r.Z,{playsinline:!0,playing:!0,controls:!0,muted:!0,loop:!0,url:"/assets/compute5.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,o.kt)("p",null,"While there are many other ways to set up such clusters, a major benefit of Metaflow is\nthat you can ",(0,o.kt)("em",{parentName:"p"},"embed an ephemeral cluster")," as a part of a larger workflow, instead of having\nto maintain the cluster separately. Learn more on ",(0,o.kt)("a",{parentName:"p",href:"distributed-computing"},"a dedicated page about distributed\ncomputing"),"."))}m.isMDXComponent=!0}}]);