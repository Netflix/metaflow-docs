"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[5958],{3410:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>m});var a=t(7462),i=(t(7294),t(3905)),o=t(2004);const r={},s="Config-Driven Experimentation",l={unversionedId:"metaflow/configuring-flows/config-driven-experimentation",id:"metaflow/configuring-flows/config-driven-experimentation",title:"Config-Driven Experimentation",description:"Usually, a Config determines how a run should behave. It is also possible to use configs, in",source:"@site/docs/metaflow/configuring-flows/config-driven-experimentation.md",sourceDirName:"metaflow/configuring-flows",slug:"/metaflow/configuring-flows/config-driven-experimentation",permalink:"/metaflow/configuring-flows/config-driven-experimentation",draft:!1,editUrl:"https://github.dev/Netflix/metaflow-docs/blob/master/docs/metaflow/configuring-flows/config-driven-experimentation.md",tags:[],version:"current",frontMatter:{},sidebar:"python",previous:{title:"Custom Config Parsers",permalink:"/metaflow/configuring-flows/custom-parsers"},next:{title:"Scalable Compute and Data",permalink:"/scaling/introduction"}},p={},m=[{value:"Benchmark: A templatized flow with pluggable modules",id:"benchmark-a-templatized-flow-with-pluggable-modules",level:2},{value:"Running with Hydra",id:"running-with-hydra",level:3},{value:"Sweep: Orchestrating and observing experiments at scale",id:"sweep-orchestrating-and-observing-experiments-at-scale",level:2}],c={toc:m};function h(e){let{components:n,...r}=e;return(0,i.kt)("wrapper",(0,a.Z)({},c,r,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"config-driven-experimentation"},"Config-Driven Experimentation"),(0,i.kt)("p",null,"Usually, a ",(0,i.kt)("inlineCode",{parentName:"p"},"Config")," determines ",(0,i.kt)("em",{parentName:"p"},"how")," a run should behave. It is also possible to use configs, in\nconjunction with a configuration manager such as ",(0,i.kt)("a",{parentName:"p",href:"https://hydra.cc"},"Hydra"),", to use configs to define\n",(0,i.kt)("em",{parentName:"p"},"what")," should be run."),(0,i.kt)("p",null,"Hydra enables you to define and generate configuration sets that parameterize an entire suite of\nMetaflow runs. By using configs, you can easily set up experiments and (hyper)parameter sweeps.\nWith the help of ",(0,i.kt)("a",{parentName:"p",href:"/metaflow/managing-flows/introduction"},"Metaflow's ",(0,i.kt)("inlineCode",{parentName:"a"},"Runner")," and ",(0,i.kt)("inlineCode",{parentName:"a"},"Deployer")," APIs"),", these runs\ncan be executed automatically."),(0,i.kt)("p",null,"This section gives two examples demonstrating the idea in practice:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"A benchmark template that allows you to choose what to run on the command line\n(",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/tree/main/hydra-benchmark"},"source"),").")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"A large-scale parameter sweep with real-time monitoring\n(",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/tree/main/hydra-sweep"},"source"),")."))),(0,i.kt)("p",null,"Clone the examples from the source repository and follow along."),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"You can run ordinary ",(0,i.kt)("a",{parentName:"p",href:"https://docs.outerbounds.com/grid-search-with-metaflow/"},"hyperparameter sweeps easily using\n",(0,i.kt)("inlineCode",{parentName:"a"},"foreach")),". The examples in this section\ncover a more advanced case where you need to alter flow-level behavior, decorators in particular,\nin experiments. ",(0,i.kt)("a",{parentName:"p",href:"/metaflow/basics#foreach"},"Start with ",(0,i.kt)("inlineCode",{parentName:"a"},"foreach"))," and come back here if it\nisn't sufficient for your needs.")),(0,i.kt)("h2",{id:"benchmark-a-templatized-flow-with-pluggable-modules"},"Benchmark: A templatized flow with pluggable modules"),(0,i.kt)("p",null,"Consider the following common scenario: You want to compare the performance of various\nimplementations across a common test setup. It should be easy to add new solutions without\nhaving to modify the benchmarking setup itself. "),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/tree/main/hydra-benchmark"},"Our example"),"\ndemonstrates the idea by measuring the performance of a simple dataframe operation -\ngrouping by hour - across three dataframe backends, Pandas, Polars, and DuckDB. Adding\na new backend is easy: Simply drop a module in ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/tree/main/hydra-benchmark/backend"},"the ",(0,i.kt)("inlineCode",{parentName:"a"},"backend"),"\ndirectory"),"\nwith a config file that specifies the dependencies needed."),(0,i.kt)("p",null,"Thanks to ",(0,i.kt)("inlineCode",{parentName:"p"},"Config"),", ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-benchmark/benchmark_flow.py"},"the shared benchmark flow,\n",(0,i.kt)("inlineCode",{parentName:"a"},"ConfigurableBenchmark")),", can modify its ",(0,i.kt)("inlineCode",{parentName:"p"},"@pypi")," to match the requirements of the chosen backend, ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-benchmark/benchmark_flow.py#L14"},"importing\nthe backend module on the\nfly"),"."),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Besides Hydra, this pattern of pluggable modules, imported on the fly with custom dependencies\nis useful in various applications. You can use it for pluggable feature encoders, models etc.")),(0,i.kt)("h3",{id:"running-with-hydra"},"Running with Hydra"),(0,i.kt)("p",null,"Imagine you want to compare the performance of the backends. You could run\n",(0,i.kt)("inlineCode",{parentName:"p"},"ConfigurableBenchmark")," three times, choosing a suitable config manually but as the number of\nbackends increases, this can become tedious."),(0,i.kt)("p",null,"Managing experiments like this is where Hydra shines. We implement ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-benchmark/benchmark_runner.py"},"a simple Hydra\napp"),"\nwhich uses ",(0,i.kt)("a",{parentName:"p",href:"/metaflow/managing-flows/runner"},"the Metaflow ",(0,i.kt)("inlineCode",{parentName:"a"},"Runner"))," to launch and manage a run.\nWe can then use the versatile syntax of Hydra to choose which experiments to run, letting Hydra\ntake care of merging each backend-specific config with ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-benchmark/config.yaml"},"a global\nconfig"),"\nautomatically."),(0,i.kt)("p",null,"The resulting setup looks like this:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:t(5428).Z,width:"1500",height:"448"})),(0,i.kt)("p",null,"As experiments are managed by Hydra, instead of running a flow directly, we launch them via\nthe Hydra app. For instance, we can test a specific backend like this:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python bechmark_runner.py +backend=pandas\n")),(0,i.kt)("p",null,"Take a look at ",(0,i.kt)("a",{parentName:"p",href:"https://hydra.cc/docs/intro/"},"the documentation of Hydra")," for details about\nits rich syntax for configuring experiments. In particular, we can use Hydra to run multiple\nexperiments using its ",(0,i.kt)("a",{parentName:"p",href:"https://hydra.cc/docs/tutorials/basic/running_your_app/multi-run/"},"Multirun\nmode"),". We can use it to\ntest all backends sequentially:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python bechmark_runner.py +backend=pandas,polars,duckdb -m\n")),(0,i.kt)("p",null,"The runner assigns a unique ",(0,i.kt)("a",{parentName:"p",href:"/metaflow/client#adding-removing-and-replacing-tags"},"Metaflow tag")," in\na set of experiments, making it easy to focus and fetch results of a Hydra run. You can see the\ncommand in action here (spoiler: DuckDB is fast!):"),(0,i.kt)(o.Z,{controls:!0,muted:!0,playsinline:!0,url:"/assets/hydra-benchmark.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,i.kt)("p",null,"Note that ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-benchmark/config.yaml#L7"},"the default\nconfiguration"),"\nincludes a ",(0,i.kt)("inlineCode",{parentName:"p"},"remote: batch")," key, which runs the experiments using ",(0,i.kt)("inlineCode",{parentName:"p"},"@batch"),". You can remove the\n",(0,i.kt)("inlineCode",{parentName:"p"},"remote")," line to execute the tests locally, or you can change it to ",(0,i.kt)("inlineCode",{parentName:"p"},"kubernetes"),"."),(0,i.kt)("h2",{id:"sweep-orchestrating-and-observing-experiments-at-scale"},"Sweep: Orchestrating and observing experiments at scale"),(0,i.kt)("p",null,"The benchmark example above relied on a finite set of manually defined configurations, one for each\nbackend. In contrast, ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/tree/main/hydra-sweep"},"this example,\n",(0,i.kt)("inlineCode",{parentName:"a"},"hydra-sweep")),",\ngenerates a set of configurations on the fly, sweeping over a grid of quantitative parameters."),(0,i.kt)("p",null,"Typically, you would use a ",(0,i.kt)("inlineCode",{parentName:"p"},"foreach")," to sweep over a parameter grid, but if the experiments\nrequire changes in decorators, Hydra comes in handy again, thanks to its native support for\n",(0,i.kt)("a",{parentName:"p",href:"https://hydra.cc/docs/patterns/configuring_experiments/#sweeping-over-experiments"},"sweeping over experiments"),".\nSince the parameter grid can be large, it is not convenient to run experiments sequentially as with ",(0,i.kt)("inlineCode",{parentName:"p"},"hydra-benchmark"),".\nWhile we could parallelize experiments in a limited fashion on our local workstation, a more robust solution\nfor large-scale experimentation is to deploy experiments to one of the ",(0,i.kt)("a",{parentName:"p",href:"/production/scheduling-metaflow-flows/introduction"},"production\norchestrators supported by Metaflow"),", which allows us\nto run hundreds of large-scale experiments in parallel."),(0,i.kt)("p",null,"We follow a similar pattern as with ",(0,i.kt)("inlineCode",{parentName:"p"},"hydra-benchmark")," above, constructing ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-sweep/sweep_deployer.py"},"a Hydra app,\n",(0,i.kt)("inlineCode",{parentName:"a"},"sweep_deployer.py"))," that\ndeploys flows using ",(0,i.kt)("a",{parentName:"p",href:"/metaflow/managing-flows/deployer"},"the ",(0,i.kt)("inlineCode",{parentName:"a"},"Deployer")," API"),". We take extra care of\nisolating deployments using ",(0,i.kt)("a",{parentName:"p",href:"/production/coordinating-larger-metaflow-projects"},(0,i.kt)("inlineCode",{parentName:"a"},"@project")," branches"),",\nso multiple sets of experiments can be run concurrently. "),(0,i.kt)("p",null,"We attach a unique tag to all runs, which allows us to fetch all results for analysis and visualization.\nThis is done by\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-sweep/sweep_analytics.py"},(0,i.kt)("inlineCode",{parentName:"a"},"SweepAnalyticsFlow")),"\nwhich updates its results automatically through a ",(0,i.kt)("inlineCode",{parentName:"p"},"@trigger")," every time an experiment finishes successfully."),(0,i.kt)("p",null,"The setup looks like this:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:t(8594).Z,width:"1333",height:"769"})),(0,i.kt)("p",null,"This pattern is applicable to any experiment that requires sweeping over configurations. To demonstrate the\nidea in practice, we use a flow,\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-sweep/torchtest.py"},(0,i.kt)("inlineCode",{parentName:"a"},"TorchPerfFlow")),", to\ntest the performance of PyTorch doing a matrix squaring operation on a varying number of CPU cores, over\na varying dimensionality of the matrix - the sweep over these parameters is defined in ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/config-examples/blob/main/hydra-sweep/config.yaml#L12"},"this Hydra\nconfig"),".\nWe adjust the ",(0,i.kt)("inlineCode",{parentName:"p"},"@resources(cpu=)")," setting through the config, which wouldn't be doable\nusing a normal ",(0,i.kt)("inlineCode",{parentName:"p"},"foreach"),"."),(0,i.kt)("p",null,"You can start the sweep, assuming you have Metaflow configured to work with Argo Workflows, by executing"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python sweep_deployer.py -m\n")),(0,i.kt)("p",null,"It will start by deploying ",(0,i.kt)("inlineCode",{parentName:"p"},"SweepAnalyticsFlow"),", followed by each individual ",(0,i.kt)("inlineCode",{parentName:"p"},"TorchPerfTest")," experiment\nwhich will produce statistics in real-time. As shown in the screen recording below, you can observe results\nthrough ",(0,i.kt)("inlineCode",{parentName:"p"},"SweepAnalyticsFlow")," that updates every time new data points appear:"),(0,i.kt)(o.Z,{controls:!0,muted:!0,playsinline:!0,url:"/assets/hydra-sweep.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}))}h.isMDXComponent=!0},8594:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/hydra-deployer-ba2e023f1f022e657933e01d7d17f3bc.png"},5428:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/hydra-runner-c4df95970a7c9f284f32d453e845ace6.png"}}]);